{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6933e2",
   "metadata": {},
   "source": [
    "# Bayesian methods of Machine Learning (Skoltech)\n",
    "\n",
    "## Home Assignment 2.  Log-Derivative trick. VAE. Mean-field approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc3d83",
   "metadata": {},
   "source": [
    "<img src=\"https://go2phystech.ru/wp-content/uploads/2021/02/skolteh.jpeg\" width=800 height=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c566e1",
   "metadata": {},
   "source": [
    "### Important information\n",
    "\n",
    "$\\textbf{Deadline}$: 23:59:59, 3 November 2023 (Friday)\\\n",
    "$\\textbf{Rules}$:\n",
    "\n",
    "- Do not redistribure materials of this homework, they belong to Skoltech.\n",
    "- This is your individual work. Please, do not consult with the other students and do not copy their work. Otherwise, you will get 0 points.\n",
    "- Please, respect the homework deadlines!\n",
    "- This HW is composed of 4 tasks with the corresponding points: task 1 - 2pts, task 2 - 2 pts, task 3 - 4 pts, task 4 - 4 pts. Overall, 12 points.\n",
    "- We have created a special telegram topic for this homework 2. There you can questions if anything is unclear. However, please do not post your solution or ask for it in the subgroup's messages, otherwise, you will get 0 points.\n",
    "- After the grades are posted, you will have one week to appeal (offline, on campus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e005c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as TD\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Bernoulli, Independent\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Union\n",
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "USE_CUDA=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122a309",
   "metadata": {},
   "source": [
    "## Task 1. Log-derivative Trick (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5197d2",
   "metadata": {},
   "source": [
    "## \n",
    "1. In seminar 6 we have encountered a problem with Monte Carlo estimation deriving the ELBO gradient at the E-step, since the distribution function $q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})$ depends on the differentiation parameters $\\boldsymbol{\\phi}$.\n",
    "\\begin{align*}\n",
    "    \\nabla_{\\boldsymbol{\\phi}} \\mathcal{L} (\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) &= \\nabla_{\\boldsymbol{\\phi}} \\int q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) \\left[\\log p(\\mathbf{x}, \\mathbf{z} | \\boldsymbol{\\theta}) - \\log q(\\mathbf{z}| \\mathbf{x}, \\boldsymbol{\\phi}) \\right] d \\mathbf{z} \\\\\n",
    "    & \\neq  \\int q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) \\nabla_{\\boldsymbol{\\phi}} \\left[\\log p(\\mathbf{x}, \\mathbf{z} | \\boldsymbol{\\theta}) - \\log q(\\mathbf{z}| \\mathbf{x}, \\boldsymbol{\\phi}) \\right] d \\mathbf{z} \\\\\n",
    "\\end{align*}\n",
    "The Reparametrization trick allowed us to skip the gradient and get a Monte Carlo estimate. \n",
    "\n",
    "    However, there is another way that uses the so-called **log-derivative trick**:\n",
    "    $$\n",
    "        \\nabla_\\xi  \\log q(\\eta| \\xi) = \\frac{\\nabla_\\xi q(\\eta| \\xi)}{q(\\eta| \\xi)}.\n",
    "    $$\n",
    "    \n",
    "    Problems: \n",
    "    1. Get the Monte Carlo estimate of the gradient using the formula for the derivative of the logarithm. (1 pt)\n",
    "    2. The final expression works significantly worse than the reparametrization trick. Namely, it has a huge variance. Try to describe the intuition why this estimation has a high variance (you need to think about what order and sign the terms in the expression will have). (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b55229",
   "metadata": {},
   "source": [
    "##### your answer is here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689874aa",
   "metadata": {},
   "source": [
    "## Task 2. VAE with no-gaussian decoder (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f234d",
   "metadata": {},
   "source": [
    "We have familiarized ourselves with the decoder model that describes the conditional distribution $p(x|z,\\theta)$. We have considered this model as gaussian distribution for simplicity. Thus, we have assumed that data is described by normal distribution with mean and covariance matrix that are trainable. Nonetheless, one can choose another distribution for certain tasks.\n",
    "\n",
    "Let $\\textbf{MNIST}$ data be the data used in this task. Our data looks contains these images:\n",
    "\n",
    "![Autoencoder reconstructions](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/ae_reconstructions.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc84de4",
   "metadata": {},
   "source": [
    "Each image of this dataset is the combination of black and white pixels. Thus, decoder tries to set either white or black color for each pixel of the generated image. So, we set either 0 or 1 for each coordinate of this generated image. As a consequence of that, the output of our decoder has 2 possible outcomes and one can take $\\textbf{bernoulli}$ distribution as $p(x|z,\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f61669",
   "metadata": {},
   "source": [
    "\n",
    "A variational autoencoder consists of two components. The first component is a probabilistic model for observations: \n",
    "\\begin{align}\n",
    "& p(x, z \\mid \\theta) =  p(z) p(x \\mid z, \\theta) \\\\\n",
    "& p(z) = \\mathcal N(z \\mid 0, I) \\\\\n",
    "& p(x \\mid z, \\theta) = \\prod_{i = 1}^D p_i(z, \\theta)^{x_i} (1 - p_i(z, \\theta))^{1 - x_i}.\n",
    "\\end{align}\n",
    "The second component is a variational approximation, used to compute the lower bound on marginal likelihood (VAE uses the negative lower bound as a loss function)\n",
    "\\begin{equation}\n",
    "q(z \\mid x, \\phi) = \\mathcal N(z \\mid \\mu(x, \\phi), \\operatorname{diag}(\\sigma^2(x, \\phi))).\n",
    "\\end{equation}\n",
    "The lower bound for probability of observing $x$ from a minibatch is\n",
    "$$ \\mathcal L(x, \\theta, \\phi) = \\mathbb E_{q(z \\mid x, \\phi)} \\left[ \\log p(x \\mid z, \\phi) + \\log p(z) - \\log q(z \\mid x, \\theta) \\right] $$\n",
    "However, it is impossible to compute this expectation. The standard practice is to approximate it with the following one-sample Monte-Carlo estimate:\n",
    "\\begin{align*}\n",
    "\\log p(x \\mid z_0, \\phi) + \\log p(z_0) - \\log q(z_0 \\mid x, \\theta) \\\\\n",
    "z_0 = \\mu(x, \\phi) + \\sigma^2(x, \\phi)^T \\varepsilon_0 \\\\\n",
    "\\varepsilon_0 \\sim \\mathcal N(0, I)\n",
    "\\end{align*}\n",
    "*Note that this choice of the Monte-Carlo estimate for expectation is crucial and is typically reffered to as* **reparametrization trick.** For more details see [Auto-encoding Variational Bayes](https://arxiv.org/abs/1312.6114) paper.\n",
    "\n",
    "Finally, to train the model we average the lower bound values over the minibatch and then maximize the average with gradient ascent:\n",
    "$$ \\frac{1}{N} \\sum_{n=1}^N \\log p(x_n \\mid z_n, \\phi) + \\log p(z_n) - \\log q(z_n \\mid x_n, \\theta) \\rightarrow \\max_{\\theta, \\phi} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40240ee",
   "metadata": {},
   "source": [
    "### Encoder and decoder\n",
    "\n",
    "$q(z\\mid x, \\theta)$ is usually called encoder and $p(x \\mid z, \\phi)$ is usually called decoder. To parametrize these distributions we introduce two neural networks:\n",
    "\n",
    "- *enc* takes $x$ as input and return $2 \\times d$-dimensional vector to parametrize mean and standard deviation of $q(z \\mid x, \\theta)$\n",
    "- *dec* takes a latent representation $z$ and returns the logits of distribution $p(x \\mid z, \\phi)$.\n",
    "\n",
    "The computational graph has a simple structure of autoencoder. The only difference is that now it uses a stochastic variable $\\varepsilon$:\n",
    "\n",
    "![vae](https://github.com/bayesgroup/deepbayes-2018/blob/master/day2_vae/vae.png?raw=true)\n",
    "\n",
    "Below we initialize a couple of simple fully-connected networks to model the two distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55cc33c",
   "metadata": {},
   "source": [
    "### 2.0 data for the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26854b",
   "metadata": {},
   "source": [
    "Download MNIST data for this experiment an d divide it to train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550de857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(root='.', train=True, download=True,\n",
    "          transform=transforms.ToTensor()),\n",
    "    batch_size=100, shuffle=True )\n",
    "\n",
    "# Test dataset\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(root='.', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80deb972",
   "metadata": {},
   "source": [
    "### 2.1 Initializtion of models  (0.5 pt)\n",
    "\n",
    "First of all, we initialize netorks for encoder and decoder  correspondingly. Below, we choose dimension of latent and data spaces. You should write appropriate architectures for encoder and decoder. (0.5 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 32  # dimension of latent space \n",
    "nh =  100 # dinesnions of intermediate representations.\n",
    "D = 28 * 28 # dimension of data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f662b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "# your code is here\n",
    "enc =  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23d423",
   "metadata": {},
   "source": [
    "Please, pay your attention! When we built decoder for $p(x|z,\\phi)$ that is normal distribution, then such decoder has 2$D$ outputs, but you should correct outputs in this case of Bernoulli distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "# your code is here\n",
    "dec =  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = enc.to(device)\n",
    "dec = dec.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43075a",
   "metadata": {},
   "source": [
    "### 2.2  VAE Loss function.  (0.5 pt)\n",
    "\n",
    "Implement the line that corresponds to the loss function for the variational autoencoder (0.5 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000362fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_vae(x, encoder, decoder):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    returns\n",
    "    1. the avergave value of negative ELBO across the minibatch x\n",
    "    2. and the output of the decoder\n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    encoder_output = encoder(x)\n",
    "    pz = Independent(Normal(loc=torch.zeros(batch_size, d).to(device),\n",
    "                            scale=torch.ones(batch_size, d).to(device)),\n",
    "                     reinterpreted_batch_ndims=1)\n",
    "    qz_x = Independent(Normal(loc=encoder_output[:, :d],\n",
    "                              scale=torch.exp(encoder_output[:, d:])),\n",
    "                       reinterpreted_batch_ndims=1)\n",
    "    \n",
    "    z = qz_x.rsample()\n",
    "    decoder_output = decoder(z)\n",
    "    px_z = Independent(Bernoulli(logits=decoder_output), \n",
    "                       reinterpreted_batch_ndims=1)\n",
    "    \n",
    "    loss = #your code is here\n",
    "    \n",
    "    return loss, decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4e01c",
   "metadata": {},
   "source": [
    "### 2.3 Training\n",
    "\n",
    "The cell below implements a simple training function that can be used for both models(encoder and decoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def train_model(loss, model, batch_size, num_epochs, learning_rate):\n",
    "    gd = torch.optim.Adam(\n",
    "        chain(*[x.parameters() for x in model\n",
    "                if (isinstance(x, nn.Module) or isinstance(x, nn.Parameter))]),\n",
    "        lr=learning_rate)\n",
    "    train_losses = []\n",
    "    test_results = []\n",
    "    for _ in range(num_epochs):\n",
    "        for i, (batch, _) in enumerate(train_loader):\n",
    "            total = len(train_loader)\n",
    "            gd.zero_grad()\n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            loss_value, _ = loss(batch, *model)\n",
    "            loss_value.backward()\n",
    "            train_losses.append(loss_value.item())\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('\\rTrain loss:', train_losses[-1],\n",
    "                      'Batch', i + 1, 'of', total, ' ' * 10, end='', flush=True)\n",
    "            gd.step()\n",
    "        test_loss = 0.\n",
    "        for i, (batch, _) in enumerate(test_loader):\n",
    "            batch = batch.view(-1, D).to(device)\n",
    "            batch_loss, _ = loss(batch, *model)\n",
    "            test_loss += (batch_loss - test_loss) / (i + 1)\n",
    "        print('\\nTest loss after an epoch: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93221be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose appropiate hyper-parameters\n",
    "# your code is here\n",
    "BATCH_SIZE = \n",
    "NUM_EPOCHS=\n",
    "LR ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfbaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model(loss_vae, model=[enc, dec], batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS, learning_rate=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a93ee2",
   "metadata": {},
   "source": [
    "### 2.4 Inference of VAE model (0.5 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde5245",
   "metadata": {},
   "source": [
    "You should write the line, where we take latent codes and apply decoder model for these latent codes. (0.5 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_vae(dec, n_samples=50):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        samples =  #your code is here\n",
    "        \n",
    "        samples = samples.view(n_samples, 28, 28).cpu().numpy()\n",
    "    return samples\n",
    "    \n",
    "def plot_samples(samples, h=5, w=10):\n",
    "    fig, axes = plt.subplots(nrows=h,\n",
    "                             ncols=w,\n",
    "                             figsize=(int(1.4 * w), int(1.4 * h)),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(samples[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9886c24",
   "metadata": {},
   "source": [
    "We use trained decoder for the inference and obtain such results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af61d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples(sample_vae(dec=dec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1662245",
   "metadata": {},
   "source": [
    "### 2.5 Plot reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb737ef",
   "metadata": {},
   "source": [
    "Reconstruction is performed according to the following scenario. We take $x$ from dataset and perform mapping for this $x$ using the encoder model $q(z|x,\\phi)$, then we make a sample from this distribution via reparametrization trick and feed this sample to the decoder model $p(x|z,\\theta)$. We beleive that the resulting recostruction will be similar to the initial data point. This way, our generated image is referred to as a reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3982d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reconstructions(loss, model):\n",
    "    with torch.no_grad():\n",
    "        batch = (test_loader.dataset.data[:25].float() / 255.)\n",
    "        batch = batch.view(-1, D).to(device)\n",
    "        _, rec = loss(batch, *model)\n",
    "        rec = torch.sigmoid(rec)\n",
    "        rec = rec.view(-1, 28, 28).cpu().numpy()\n",
    "        batch = batch.view(-1, 28, 28).cpu().numpy()\n",
    "    \n",
    "        fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                                 subplot_kw={'xticks': [], 'yticks': []})\n",
    "        for i in range(25):\n",
    "            axes[i % 5, 2 * (i // 5)].imshow(batch[i], cmap='gray')\n",
    "            axes[i % 5, 2 * (i // 5) + 1].imshow(rec[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstructions(loss_vae, [enc, dec])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0f4a3",
   "metadata": {},
   "source": [
    "### 2.6 Plot interpolations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556a2b7",
   "metadata": {},
   "source": [
    "The first attempt to understand latent space of VAE is interploations. We take two latent codes $z_{0}$ and $z_{1}$ and build the forward line between them. Then we make samples along this line and decode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f313b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interpolations(encoder, decoder):\n",
    "    with torch.no_grad():\n",
    "        batch = (test_loader.dataset.data[:10].float() / 255.)\n",
    "        batch = batch.view(-1, D).to(device)\n",
    "        batch = encoder(batch)\n",
    "        z_0 = batch[:5, :d].view(5, 1, d)\n",
    "        z_1 = batch[5:, :d].view(5, 1, d)\n",
    "        \n",
    "        alpha = torch.linspace(0., 1., 10).to(device)\n",
    "        alpha = alpha.view(1, 10, 1)\n",
    "        \n",
    "        interpolations_z = (z_0 * alpha + z_1 * (1 - alpha))\n",
    "        interpolations_z = interpolations_z.view(50, d)\n",
    "        interpolations_x = torch.sigmoid(decoder(interpolations_z))\n",
    "        interpolations_x = interpolations_x.view(5, 10, 28, 28).cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(14, 7),\n",
    "                             subplot_kw={'xticks': [], 'yticks': []})\n",
    "    for i in range(50):\n",
    "        axes[i // 10, i % 10].imshow(interpolations_x[i // 10, i % 10], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interpolations(enc, dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4cd76",
   "metadata": {},
   "source": [
    "### 2.7 Plot latent space of VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2c7dd5",
   "metadata": {},
   "source": [
    "Also, one can learn the structure of latent spaces with the help of the methods of geometric ml(metric learning) such as [T-sne](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(objects, labels):\n",
    "    from sklearn.manifold import TSNE\n",
    "    embeddings = TSNE(n_components=2).fit_transform(objects)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for k in range(10):\n",
    "        embeddings_for_k = embeddings[labels == k]\n",
    "        plt.scatter(embeddings_for_k[:, 0], embeddings_for_k[:, 1],\n",
    "                    label='{}'.format(k))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch = (test_loader.dataset.data[:1000].float() / 255.)\n",
    "    batch = batch.view(-1, D).to(device)\n",
    "\n",
    "    latent_variables = enc(batch)[:, :d]\n",
    "    latent_variables = latent_variables.cpu().numpy()\n",
    "    labels = test_loader.dataset.targets[:1000].numpy()\n",
    "\n",
    "plot_tsne(latent_variables, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe459cbe",
   "metadata": {},
   "source": [
    "###   2.8 Observations (0.5 pts)\n",
    "\n",
    "Write down your observations on the plots above and answer the following questions:\n",
    "  \n",
    "- Is the latent space regularly covered? \n",
    "- Is there any correlation between the resulting T-SNE encoding and the digit label?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d82315f",
   "metadata": {},
   "source": [
    "###### your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c487167",
   "metadata": {},
   "source": [
    "## Task 3. Mean-field approximation (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93369454",
   "metadata": {},
   "source": [
    "We have already built approximation by mean-field methodology during the 5th seminar. This task is almost the same, but you will be asked to try out another distributions.\n",
    "\n",
    "Consider the following model for i.i.d data $\\mathcal{D}=\\{x_1,\\dots,x_N\\}$, $N\\geq2$ and $x_{i} \\in \\mathbb{R}$\n",
    "\n",
    "We assume that our data distribution is described by a uniform distribution with the following prior distribution over the parameters:\n",
    "\\begin{align*}\n",
    "p(x \\mid \\lambda)&=\\operatorname{Uniform}(x\\mid0,\\; \\lambda)\\\\\n",
    "p(\\lambda \\mid \\tau) &= \\operatorname{Pareto}(\\lambda\\mid \\gamma_0,\\; \\alpha_0\\tau),\\\\\n",
    "p(\\tau) &= \\operatorname{Gamma}(\\tau\\mid u_0,\\; v_0),\n",
    "\\end{align*}\n",
    "\n",
    "$\\textbf{Full task}:$ Find the approximation of true posterior $p(\\lambda,\\tau\\mid\\mathcal{D})$ using mean-field approximation $q(\\lambda,\\tau)=q_{\\lambda}(\\lambda)q_{\\tau}(\\tau)$\n",
    "\n",
    "$\\textbf{Recap}:$\n",
    "\n",
    "Densities:\n",
    "\\begin{align*}\n",
    "\\operatorname{Uniform}(x\\mid a, b) &= \\frac{1}{b-a},\\;\\; x \\in [a, b]\\\\\n",
    "\\operatorname{Pareto}(x\\mid x_m, \\alpha) &= \\frac{\\alpha x_m^{\\alpha}}{x^{\\alpha+1}},\\;\\; x \\geq x_m\\\\\n",
    "\\operatorname{Gamma}(x\\mid\\alpha, \\beta) &= \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x},\\;\\; x \\geq 0\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Moments:\n",
    "$$\n",
    "X\\sim\\operatorname{Gamma}(\\alpha, \\beta)\\Rightarrow \\mathbb{E}X=\\frac{\\alpha}{\\beta}\n",
    "$$\n",
    "$$\n",
    "X\\sim\\operatorname{Pareto}(x_m, \\alpha), \\text{ and } \\alpha>1 \\Rightarrow \\mathbb{E}X=\\frac{\\alpha x_m}{\\alpha-1}, \\text{ and }\\;\\mathbb{E}\\ln X=\\ln x_m + \\frac{1}{\\alpha}\n",
    "$$\n",
    "\n",
    "$\\textbf{Hint}$:\n",
    "Don't forget about conjugate distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd1346e",
   "metadata": {},
   "source": [
    "### 3.1 Derive formulas for the first parameter (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bf30e",
   "metadata": {},
   "source": [
    "Firstly, you should derive and get formulas for $ q_{\\lambda}(\\lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753c055",
   "metadata": {},
   "source": [
    "##### your derivation is here (latex code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a074ec1",
   "metadata": {},
   "source": [
    "### 3.2 Derive formulas for the second parameter (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993616b9",
   "metadata": {},
   "source": [
    "Secondly, you should derive and get formulas for $ q_{\\tau}(\\tau)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705585f",
   "metadata": {},
   "source": [
    "###### your derivation is here (latex code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a764c",
   "metadata": {},
   "source": [
    "### 3.3 Iterative processes of mean-field  approximation (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a14bc",
   "metadata": {},
   "source": [
    "Code the iterative recomputation process for this task as it has been done in the 5th seminar. Run your process and plot your approximation for $p(\\lambda,\\tau\\mid\\mathcal{D})$ for all iterations. It means that you should demonstrate how your approximation changes as your method is training.\n",
    "\n",
    "$\\textbf{Note}$: You are required to demonstrate all the relevant calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b1538",
   "metadata": {},
   "source": [
    "## Task 4. VAE on CIFAR-10 dataset (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee784d",
   "metadata": {},
   "source": [
    "In this task you will implement VAE model for CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8899275",
   "metadata": {},
   "source": [
    "### 4.1 utils for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKS_FONT_SIZE = 12\n",
    "LEGEND_FONT_SIZE = 12\n",
    "LABEL_FONT_SIZE = 14\n",
    "TITLE_FONT_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be386aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(train_losses, test_losses, logscale_y=False, logscale_x=False):\n",
    "    n_train = len(train_losses[list(train_losses.keys())[0]])\n",
    "    n_test = len(test_losses[list(train_losses.keys())[0]])\n",
    "    x_train = np.linspace(0, n_test - 1, n_train)\n",
    "    x_test = np.arange(n_test)\n",
    "\n",
    "    plt.figure()\n",
    "    for key, value in train_losses.items():\n",
    "        plt.plot(x_train, value, label=key + '_train')\n",
    "\n",
    "    for key, value in test_losses.items():\n",
    "        plt.plot(x_test, value, label=key + '_test')\n",
    "\n",
    "    if logscale_y:\n",
    "        plt.semilogy()\n",
    "    \n",
    "    if logscale_x:\n",
    "        plt.semilogx()\n",
    "\n",
    "    plt.legend(fontsize=LEGEND_FONT_SIZE)\n",
    "    plt.xlabel('Epoch', fontsize=LABEL_FONT_SIZE)\n",
    "    plt.ylabel('Loss', fontsize=LABEL_FONT_SIZE)\n",
    "    plt.xticks(fontsize=TICKS_FONT_SIZE)\n",
    "    plt.yticks(fontsize=TICKS_FONT_SIZE)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR10():\n",
    "    train_data = torchvision.datasets.CIFAR10(root=\"./\", train=True, download=True)\n",
    "    test_data = torchvision.datasets.CIFAR10(root=\"./\", train=False, download=True)\n",
    "    train_data, test_data = train_data.data, test_data.data\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f691290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_dataset(name: str):\n",
    "   \n",
    "    if name == \"cifar10\":\n",
    "        return load_CIFAR10()\n",
    "    else:\n",
    "        raise ValueError(\"The argument name must have the value  'cifar10'\")\n",
    "        \n",
    "\n",
    "def load_dataset(\n",
    "    name, flatten: bool = False, binarize: bool = True\n",
    "):\n",
    "\n",
    "    train_data, test_data = _load_dataset(name)\n",
    "\n",
    "    train_data = train_data.astype(\"float32\")\n",
    "    test_data = test_data.astype(\"float32\")\n",
    "\n",
    "    if binarize:\n",
    "        train_data = (train_data > 128).astype(\"float32\")\n",
    "        test_data = (test_data > 128).astype(\"float32\")\n",
    "    else:\n",
    "        train_data = train_data / 255.0\n",
    "        test_data = test_data / 255.0\n",
    "\n",
    "    train_data = np.transpose(train_data, (0, 3, 1, 2))\n",
    "    test_data = np.transpose(test_data, (0, 3, 1, 2))\n",
    "\n",
    "    if flatten:\n",
    "        train_data = train_data.reshape(len(train_data.shape[0]), -1)\n",
    "        test_data = test_data.reshape(len(train_data.shape[0]), -1)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da871b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(\n",
    "    samples,\n",
    "    title,\n",
    "    figsize=None,\n",
    "    nrow=None,\n",
    ") -> None:\n",
    "    \n",
    "    if isinstance(samples, np.ndarray):\n",
    "        samples = torch.FloatTensor(samples)\n",
    "    if nrow is None:\n",
    "        nrow = int(np.sqrt(len(samples)))\n",
    "    grid_samples = make_grid(samples, nrow=nrow)\n",
    "\n",
    "    grid_img = grid_samples.permute(1, 2, 0)\n",
    "    if figsize is None:\n",
    "        figsize = (6, 6)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(title, fontsize=TITLE_FONT_SIZE)\n",
    "    plt.imshow(grid_img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_images(data: np.ndarray, title: str) -> None:\n",
    "    idxs = np.random.choice(len(data), replace=False, size=(100,))\n",
    "    images = data[idxs]\n",
    "    show_samples(images, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8292d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, use_cuda, loss_key='total'):\n",
    "    model.train()\n",
    "\n",
    "    stats = defaultdict(list)\n",
    "    for x in train_loader:\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        losses = model.loss(x)\n",
    "        optimizer.zero_grad()\n",
    "        losses[loss_key].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        for k, v in losses.items():\n",
    "            stats[k].append(v.item())\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, use_cuda):\n",
    "    model.eval()\n",
    "    stats = defaultdict(float)\n",
    "    with torch.no_grad():\n",
    "        for x in data_loader:\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "            losses = model.loss(x)\n",
    "            for k, v in losses.items():\n",
    "                stats[k] += v.item() * x.shape[0]\n",
    "\n",
    "        for k in stats.keys():\n",
    "            stats[k] /= len(data_loader.dataset)\n",
    "    return stats\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    epochs,\n",
    "    lr,\n",
    "    use_tqdm=False,\n",
    "    use_cuda=False,\n",
    "    loss_key='total_loss'\n",
    "):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = defaultdict(list)\n",
    "    test_losses = defaultdict(list)\n",
    "    forrange = tqdm(range(epochs)) if use_tqdm else range(epochs)\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    for epoch in forrange:\n",
    "        model.train()\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, use_cuda, loss_key)\n",
    "        test_loss = eval_model(model, test_loader, use_cuda)\n",
    "\n",
    "        for k in train_loss.keys():\n",
    "            train_losses[k].extend(train_loss[k])\n",
    "            test_losses[k].append(test_loss[k])\n",
    "    return dict(train_losses), dict(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_KL(mean_1, log_std_1, mean_2=None, log_std_2=None):\n",
    "    \"\"\"\n",
    "        This function should return the value of KL(p1 || p2),\n",
    "        where p1 = Normal(mean_1, exp(log_std_1)), p2 = Normal(mean_2, exp(log_std_2) ** 2).\n",
    "        If mean_2 and log_std_2 are None values, we will use standard normal distribution.\n",
    "        Note that we consider the case of diagonal covariance matrix.\n",
    "    \"\"\"\n",
    "    if mean_2 is None:\n",
    "        mean_2 = torch.zeros_like(mean_1)\n",
    "    if log_std_2 is None:\n",
    "        log_std_2 = torch.zeros_like(log_std_1)\n",
    "\n",
    "    first = 1 / torch.exp(log_std_2) ** 2 * torch.exp(log_std_1) ** 2\n",
    "    \n",
    "    second = (mean_2 - mean_1) * (1 / torch.exp(log_std_2) ** 2) * (mean_2 - mean_1)\n",
    "\n",
    "    third = 1\n",
    "\n",
    "    fourth = torch.log((torch.exp(log_std_2) ** 2) / (torch.exp(log_std_1) ** 2))\n",
    "\n",
    "    return 1/2 * (first + second - third + fourth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_nll(x, mean, log_std):\n",
    "    \"\"\"\n",
    "        This function should return the negative log likelihood log p(x),\n",
    "        where p(x) = Normal(x | mean, exp(log_std) ** 2).\n",
    "        Note that we consider the case of diagonal covariance matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    return log_std + 0.5 * torch.log(torch.tensor(2) * np.pi) + (x - mean) * torch.exp(-2 * log_std) / 2 * (x - mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84fc36a",
   "metadata": {},
   "source": [
    "### 4.2 Uploading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load_dataset('cifar10', flatten=False, binarize=False)\n",
    "visualize_images(train_data, 'CIFAR10 samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094501f1",
   "metadata": {},
   "source": [
    "Here the model architecture will be almost the same as in seminar 7 with the following differences:\n",
    "* Now our encoder and decoder will be convolutional.\n",
    "* We do not fit the covariance matrix $\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z})$ in the generative distribution $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$. We assume that it is identical ($\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}) = \\mathbf{I}$). We will use the $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z})$ means of the generative distribution $p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})$ as model samples.\n",
    "* Model objective is slightly modified ELBO:\n",
    "$$\n",
    "    \\mathcal{L}(\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) = \\mathbb{E}_{q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})} \\log p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) - \\beta * KL (q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) || p(\\mathbf{z})).\n",
    "$$\n",
    "Here we introduce the parameter $\\beta$. It reweights KL term in the total loss. We will discuss the choice of this parameter later in the course. In this exercise you have to play with it, starting with the value $\\beta = 1$ (standard ELBO)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3c90e",
   "metadata": {},
   "source": [
    "### 4.3 Convoluitonal Encoder (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe99ab",
   "metadata": {},
   "source": [
    "In this , you should define convolutional encoder that will return means and diagonal deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, input_shape, n_latent):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.n_latent = n_latent\n",
    "        # ====\n",
    "        # your code\n",
    "        # the possible variant of the architecture:\n",
    "        # conv2d(32) -> relu -> conv(64) -> relu -> conv(128) -> relu -> conv(256) -> fc(2 * n_latent)\n",
    "        # but we encourage you to create your own\n",
    "        \n",
    "        # ====\n",
    "         \n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) apply convs\n",
    "        # 2) reshape the output to 2d matrix for last fc layer\n",
    "        # 3) apply fc layer\n",
    "        \n",
    "        # ====\n",
    "        \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cbfee",
   "metadata": {},
   "source": [
    "### 4.4 Convolutional decoder (1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc313d",
   "metadata": {},
   "source": [
    "In this , you should define convolutional decoder that will return your generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e74e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, n_latent, output_shape):\n",
    "        super().__init__()\n",
    "        self.n_latent = n_latent\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "        self.base_size = (128, output_shape[1] // 8, output_shape[2] // 8)\n",
    "        # ====\n",
    "        # your code\n",
    "        # the possible variant of the architecture:\n",
    "        # fc -> conv2dtranspose(128) -> relu -> conv2dtranspose(64) -> relu \n",
    "        # -> conv2dtranspose(32) -> relu -> conv2dtranspose(3)\n",
    "        # but we encourage you to create your own architecture\n",
    "        \n",
    "        # ====\n",
    "        \n",
    "\n",
    "    def forward(self, z):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) apply fc layer\n",
    "        # 2) reshape the output to 4d tensor \n",
    "        # 3) apply conv layers\n",
    "        \n",
    "        # ====\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479beb10",
   "metadata": {},
   "source": [
    "### 4.5 Convolutional VAE model (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5615e7",
   "metadata": {},
   "source": [
    "Now it is time to implement VAE model for image dataset.\n",
    "\n",
    "- Firstly, you should fill in the ```forward``` function (1 pt)\n",
    "- Secondly, you should fill in the ```loss``` function (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, input_shape, n_latent, beta=1):\n",
    "        super().__init__()\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.n_latent = n_latent\n",
    "        self.beta = beta\n",
    "      \n",
    "        self.encoder = ConvEncoder(self.input_shape, self.n_latent)\n",
    "        self.decoder = ConvDecoder(self.n_latent, self.input_shape)\n",
    "\n",
    "    def prior(self, n, use_cuda=True):\n",
    "     \n",
    "        z = torch.randn(n, self.n_latent).cuda()\n",
    "        if use_cuda:\n",
    "            z = z.cuda()\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) apply encoder to get mu_z, log_std_z\n",
    "        # 2) apply reparametrization trick (use self.prior)\n",
    "        # 3) apply decoder to get mu_x (which corresponds to reconstructed x)\n",
    "        \n",
    "        # ====\n",
    "\n",
    "        \n",
    "        \n",
    "    def loss(self, x):\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) make forward step to get mu_z, log_std_z, x_recon\n",
    "        # 2) calculate recon_loss (use get_normal_nll)\n",
    "        # 3) calcucalte kl_loss (use get_normal_KL)\n",
    "        \n",
    "        # ==== \n",
    "   \n",
    "\n",
    "    def sample(self, n):\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            x_recon = self.decoder(self.prior(n))\n",
    "            samples = torch.clamp(x_recon, -1, 1)\n",
    "        return samples.cpu().numpy() * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bbe0f",
   "metadata": {},
   "source": [
    "### 4.6 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48117f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "\n",
    "BATCH_SIZE = # any adequate value\n",
    "EPOCHS =    # < 16\n",
    "LR =          # < 1e-3\n",
    "N_LATENS =    # 128 < _ < 1024\n",
    "BETA =         # 0.1 < _ < 10\n",
    "# ====\n",
    "\n",
    "# we center the data, because it helps the model to fit better\n",
    "centered_train_data = train_data * 2 - 1\n",
    "centered_test_data = test_data * 2 - 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(centered_train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(centered_test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = ConvVAE((3, 32, 32), N_LATENS, BETA)\n",
    "\n",
    "train_losses, test_losses = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    epochs=EPOCHS, \n",
    "    lr=LR, \n",
    "    loss_key='elbo_loss', \n",
    "    use_tqdm=True, \n",
    "    use_cuda=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65630d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test_losses.items():\n",
    "    print('{}: {:.4f}'.format(key, value[-1]))\n",
    "plot_training_curves(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bada5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.sample(100)\n",
    "USE_CUDA=True\n",
    "x = next(iter(test_loader))[:50]\n",
    "\n",
    "if USE_CUDA:\n",
    "    x = x.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    z, _ = model.encoder(x)\n",
    "    x_recon = torch.clamp(model.decoder(z), -1, 1)\n",
    "reconstructions = torch.stack((x, x_recon), dim=1).view(-1, 3, 32, 32) * 0.5 + 0.5\n",
    "reconstructions = reconstructions.cpu().numpy()\n",
    "\n",
    "x = next(iter(test_loader))[:20].cuda()\n",
    "with torch.no_grad():\n",
    "    z, _ = model.encoder(x)\n",
    "    z1, z2 = z.chunk(2, dim=0)\n",
    "    interps = [model.decoder(z1 * (1 - alpha) + z2 * alpha) for alpha in np.linspace(0, 1, 10)]\n",
    "    interps = torch.stack(interps, dim=1).view(-1, 3, 32, 32)\n",
    "    interps = torch.clamp(interps, -1, 1) * 0.5 + 0.5\n",
    "interps = interps.cpu().numpy()\n",
    "\n",
    "show_samples(reconstructions, 'CIFAR10 reconstructions')\n",
    "show_samples(samples, 'CIFAR10 samples')\n",
    "show_samples(interps, 'CIFAR10 interpolation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b63b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
